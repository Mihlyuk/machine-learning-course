{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import re\n",
    "import nltk\n",
    "import nltk.stem.porter\n",
    "import email.message\n",
    "import operator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 23. Создайте свой набор данных из оригинального корпуса текстов - http://spamassassin.apache.org/old/publiccorpus/.\n",
    "#### 24. Постройте собственный словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    file = open(filename, 'r')\n",
    "    content = file.read()\n",
    "    file.close()\n",
    "    return content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def tokenizeEmail(email_contents):\n",
    "    email_contents = email_contents.lower()\n",
    "    email_contents = re.sub('<[^<>]+>', ' ', email_contents)\n",
    "    email_contents = re.sub('[0-9]+', 'number', email_contents)\n",
    "    email_contents = re.sub('(http|https)://[^\\s]*', 'httpaddr', email_contents)\n",
    "    email_contents = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email_contents)\n",
    "    email_contents = re.sub('[$]+', 'dollar', email_contents)\n",
    "    email_contents = re.sub('\\s+', ' ', email_contents)\n",
    "    \n",
    "    # Tokenize Email\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    tokens = re.split('_|number|\\W', email_contents)\n",
    "    \n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName, with_names=False):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath, with_names)\n",
    "        else:\n",
    "            allFiles.append((dirName, fullPath)) if with_names else allFiles.append(fullPath)        \n",
    "                \n",
    "    return allFiles     "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "'Done 1000 / 10752, good: 862, bad: 138\n",
      "'Done 2000 / 10752, good: 1749, bad: 251\n",
      "'Done 3000 / 10752, good: 2637, bad: 363\n",
      "'Done 4000 / 10752, good: 3562, bad: 438\n",
      "'Done 5000 / 10752, good: 4508, bad: 492\n",
      "'Done 6000 / 10752, good: 5441, bad: 559\n",
      "'Done 7000 / 10752, good: 6305, bad: 695\n",
      "'Done 8000 / 10752, good: 7238, bad: 762\n",
      "'Done 9000 / 10752, good: 8180, bad: 820\n",
      "'Done 10000 / 10752, good: 9109, bad: 891\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "public_corpus_files = getListOfFiles('data/Lab 5/public_corpus')\n",
    "\n",
    "good_files = 0\n",
    "bad_files = 0\n",
    "all_tokens = []\n",
    "\n",
    "for index, public_corpus_file in enumerate(public_corpus_files, start=1):\n",
    "    try:\n",
    "        file_contents = readFile(public_corpus_file)\n",
    "        b = email.message_from_string(file_contents)\n",
    "        if b.is_multipart():\n",
    "            for payload in b.get_payload():\n",
    "                tokens = tokenizeEmail(payload.get_payload())\n",
    "                all_tokens.append(tokens)\n",
    "        else:\n",
    "            tokens = tokenizeEmail(b.get_payload())\n",
    "            all_tokens.append(tokens)\n",
    "            \n",
    "        good_files += 1\n",
    "    except:\n",
    "        bad_files += 1\n",
    "    \n",
    "    if index % 1000 == 0:\n",
    "        print(f\"'Done {index} / {len(public_corpus_files)}, good: {good_files}, bad: {bad_files}\")\n",
    "\n",
    "all_tokens_list = [item for sublist in all_tokens for item in sublist]\n",
    "all_tokens_list = list(filter(lambda x: len(x) > 0, all_tokens_list))\n",
    "all_tokens = set(all_tokens_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "all_tokens_grouped = {}\n",
    "for token in all_tokens_list:\n",
    "    all_tokens_grouped[token] = all_tokens_grouped.get(token, 0) + 1\n",
    "\n",
    "tokens5000 = sorted(all_tokens_grouped.items(), key=operator.itemgetter(1), reverse=True)[:5000]\n",
    "\n",
    "open('data/Lab 5/vocabPublicCorpus.txt', 'w').close()\n",
    "with open('data/Lab 5/vocabPublicCorpus.txt', 'a') as file:\n",
    "    for token_index, token in enumerate(tokens5000, start=1):\n",
    "        token_name, tokens_number = token\n",
    "        file.write(f'{token_index}\\t{token_name}\\t{tokens_number}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "4982\talternate\t45\n4983\tantivirus\t45\n4984\tclever\t45\n4985\tcertificate\t45\n4986\teastern\t45\n4987\tmotorola\t45\n4988\tadobe\t45\n4989\tresidence\t45\n4990\tlocked\t45\n4991\tfca\t45\n4992\tbcd\t45\n4993\tdac\t45\n4994\tfbf\t45\n4995\tslower\t45\n4996\tinformative\t45\n4997\tchips\t45\n4998\tindividually\t45\n4999\tau\t45\n5000\tuninstall\t45\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "file_contents = readFile('data/Lab 5/vocabPublicCorpus.txt').split(\"\\n\")\n",
    "print(\"\\n\".join(file_contents[len(file_contents) - 20:len(file_contents)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 25. Как изменилось качество классификации? Почему?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def getVocabList(file='vocab.txt'):\n",
    "    vocab = {}\n",
    "    for line in open(f'data/Lab 5/{file}', 'r'):\n",
    "        (val, key, *others) = line.split()\n",
    "        vocab[key] = int(val)\n",
    "    return vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def processEmail(email_contents, vocab_file='vocab.txt'):\n",
    "    vocab = getVocabList(vocab_file)\n",
    "    word_indices = []\n",
    "    email_contents = email_contents.lower()\n",
    "    email_contents = re.sub('<[^<>]+>', ' ', email_contents)\n",
    "    email_contents = re.sub('[0-9]+', 'number', email_contents)\n",
    "    email_contents = re.sub('(http|https)://[^\\s]*', 'httpaddr', email_contents)\n",
    "    email_contents = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email_contents)\n",
    "    email_contents = re.sub('[$]+', 'dollar', email_contents)\n",
    "    email_contents = re.sub('\\s+', ' ', email_contents)\n",
    "    \n",
    "    # Tokenize Email\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    tokens = re.split('_|number|\\W', email_contents)\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = re.sub('[^a-zA-Z0-9]', '', token)\n",
    "        token = stemmer.stem(token)\n",
    "        if len(token) < 1:\n",
    "            continue\n",
    "        if token in vocab:\n",
    "            word_indices.append(vocab[token])\n",
    "            \n",
    "    return word_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def emailFeatures(word_indices, number=1898):\n",
    "    features = np.zeros((number + 1,), dtype=int)\n",
    "    for w in word_indices:\n",
    "        features[w] = 1\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "'Done 1000 / 10752\n",
      "'Done 2000 / 10752\n",
      "'Done 3000 / 10752\n",
      "'Done 4000 / 10752\n",
      "'Done 5000 / 10752\n",
      "'Done 6000 / 10752\n",
      "'Done 7000 / 10752\n",
      "'Done 8000 / 10752\n",
      "'Done 9000 / 10752\n",
      "'Done 10000 / 10752\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "public_corpus_files = getListOfFiles('data/Lab 5/public_corpus', True)\n",
    "good_files = 0\n",
    "bad_files = 0\n",
    "all_tokens = []\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for index, public_corpus_file in enumerate(public_corpus_files, start=1):\n",
    "    dir_name, file_path = public_corpus_file\n",
    "    try:\n",
    "        file_contents = readFile(file_path)\n",
    "        word_indices = processEmail(file_contents, 'vocabPublicCorpus.txt')\n",
    "        X.append(emailFeatures(word_indices, 4999))\n",
    "        Y.append(1) if re.search(r'spam', dir_name) else Y.append(0)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if index % 1000 == 0:\n",
    "        print(f\"'Done {index} / {len(public_corpus_files)}\")\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "Xtrain = X[:6000]\n",
    "Ytrain = Y[:6000]\n",
    "\n",
    "Xval = X[6001:9000]\n",
    "Yval = Y[6001:9000]\n",
    "\n",
    "Xtest = X[9001:]\n",
    "Ytest = Y[9001:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Test Accuracy:  96.23287671232876\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = svm.SVC(C=10, kernel='rbf', gamma=1 / (2 * 10 ** 2))\n",
    "model.fit(Xtrain, Ytrain)\n",
    "p = model.predict(Xtest)\n",
    "print('Test Accuracy: ', np.mean(p == Ytest) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Качество классификации получилось немного меньше, думаю это можно объяснить тем, что мой словарь содержал большое количество общих слов, \n",
    "которые я не знал как полностью отфильтровать, и которые представляли из себя бесполезные признаки."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}